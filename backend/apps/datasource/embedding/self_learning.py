"""
è‡ªæˆ‘å­¦ä¹ å¼•æ“
ä»ç”¨æˆ·åé¦ˆå’ŒæŸ¥è¯¢å†å²ä¸­å­¦ä¹ ï¼Œä¸æ–­å¢å¼ºè¯­ä¹‰ç†è§£èƒ½åŠ›

åŠŸèƒ½ï¼š
1. åé¦ˆæ”¶é›†ï¼šè®°å½•ç”¨æˆ·å¯¹SQLç»“æœçš„è¯„ä»·ï¼ˆğŸ‘/ğŸ‘ï¼‰
2. æ¨¡å¼å­¦ä¹ ï¼šä»æˆåŠŸçš„æŸ¥è¯¢ä¸­å­¦ä¹ è¯­ä¹‰æ¨¡å¼
3. æƒé‡è°ƒæ•´ï¼šæ ¹æ®åé¦ˆè‡ªåŠ¨è°ƒæ•´å…³é”®è¯æƒé‡
4. è®°å¿†åº“ï¼šå­˜å‚¨æˆåŠŸæ¡ˆä¾‹ï¼Œæ”¯æŒç›¸ä¼¼æŸ¥è¯¢æ¨è
5. è‡ªé€‚åº”ä¼˜åŒ–ï¼šæŒç»­æ”¹è¿›æœç´¢æ•ˆæœ
"""

import json
import time
import hashlib
import pickle
import os
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field, asdict
from datetime import datetime, timedelta
from collections import defaultdict
from pathlib import Path
import threading
import numpy as np

from common.utils.utils import SQLBotLogUtil
from apps.ai_model.embedding import EmbeddingModelCache


@dataclass
class QueryFeedback:
    """æŸ¥è¯¢åé¦ˆè®°å½•"""
    query_id: str
    question: str
    generated_sql: str
    feedback: str  # "positive", "negative"
    feedback_time: datetime
    user_id: Optional[str] = None
    session_id: Optional[str] = None
    matched_tables: List[str] = field(default_factory=list)
    matched_fields: List[str] = field(default_factory=list)
    matched_enums: List[str] = field(default_factory=list)
    relevance_scores: Dict[str, float] = field(default_factory=dict)


@dataclass
class LearnedPattern:
    """å­¦ä¹ åˆ°çš„è¯­ä¹‰æ¨¡å¼"""
    pattern_id: str
    question_pattern: str
    matched_table: str
    matched_field: Optional[str] = None
    success_count: int = 0
    failure_count: int = 0
    confidence: float = 0.0
    keywords: List[str] = field(default_factory=list)
    embeddings: Optional[List[float]] = None
    last_updated: datetime = field(default_factory=datetime.now)


@dataclass
class KeywordWeight:
    """å…³é”®è¯æƒé‡"""
    keyword: str
    weight: float
    success_count: int = 0
    failure_count: int = 0
    table_associations: Dict[str, int] = field(default_factory=dict)


@dataclass
class MemoryItem:
    """è®°å¿†åº“æ¡ç›®"""
    question: str
    sql: str
    table: str
    keywords: List[str]
    embedding: List[float]
    success_count: int = 1
    last_used: datetime = field(default_factory=datetime.now)
    related_questions: List[str] = field(default_factory=list)


class SelfLearningEngine:
    """
    è‡ªæˆ‘å­¦ä¹ å¼•æ“
    ä»ç”¨æˆ·åé¦ˆä¸­æŒç»­å­¦ä¹ å’Œä¼˜åŒ–
    """

    _instance = None
    _lock = threading.Lock()

    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return
        self._initialized = True

        self.feedback_history: List[QueryFeedback] = []
        self.learned_patterns: Dict[str, LearnedPattern] = {}
        self.keyword_weights: Dict[str, KeywordWeight] = {}
        self.memory_bank: Dict[str, MemoryItem] = {}
        self.query_stats: Dict[str, int] = defaultdict(int)
        self.table_stats: Dict[str, Dict[str, int]] = defaultdict(lambda: defaultdict(int))

        self.embedding_model = None
        self._embedding_lock = threading.Lock()

        self._load_data()

    def _get_embedding_model(self):
        """è·å–Embeddingæ¨¡å‹"""
        if self.embedding_model is None:
            with self._embedding_lock:
                if self.embedding_model is None:
                    try:
                        self.embedding_model = EmbeddingModelCache.get_model()
                    except Exception as e:
                        SQLBotLogUtil.warning(f"æ— æ³•åŠ è½½Embeddingæ¨¡å‹: {e}")
                        return None
        return self.embedding_model

    def _get_data_path(self) -> str:
        """è·å–æ•°æ®å­˜å‚¨è·¯å¾„"""
        import os
        # ä½¿ç”¨ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„
        current_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
        data_dir = os.path.join(current_dir, 'data', 'self_learning')
        os.makedirs(data_dir, exist_ok=True)
        return data_dir

    def _get_file_path(self, name: str) -> str:
        """è·å–æ•°æ®æ–‡ä»¶è·¯å¾„"""
        return os.path.join(self._get_data_path(), f"{name}.pkl")

    def _load_data(self):
        """åŠ è½½å†å²æ•°æ®"""
        try:
            files = ['feedback', 'patterns', 'keywords', 'memory']
            for name in files:
                filepath = self._get_file_path(name)
                if os.path.exists(filepath):
                    with open(filepath, 'rb') as f:
                        data = pickle.load(f)
                    if name == 'feedback':
                        self.feedback_history = data
                    elif name == 'patterns':
                        self.learned_patterns = data
                    elif name == 'keywords':
                        self.keyword_weights = data
                    elif name == 'memory':
                        self.memory_bank = data

            SQLBotLogUtil.info(f"è‡ªæˆ‘å­¦ä¹ æ•°æ®åŠ è½½å®Œæˆ: "
                             f"åé¦ˆ{len(self.feedback_history)}, "
                             f"æ¨¡å¼{len(self.learned_patterns)}, "
                             f"å…³é”®è¯{len(self.keyword_weights)}, "
                             f"è®°å¿†{len(self.memory_bank)}")
        except Exception as e:
            SQLBotLogUtil.warning(f"åŠ è½½è‡ªæˆ‘å­¦ä¹ æ•°æ®å¤±è´¥: {e}")

    def _save_data(self):
        """ä¿å­˜æ•°æ®"""
        try:
            for name, data in [
                ('feedback', self.feedback_history),
                ('patterns', self.learned_patterns),
                ('keywords', self.keyword_weights),
                ('memory', self.memory_bank)
            ]:
                filepath = self._get_file_path(name)
                with open(filepath, 'wb') as f:
                    pickle.dump(data, f)
        except Exception as e:
            SQLBotLogUtil.warning(f"ä¿å­˜è‡ªæˆ‘å­¦ä¹ æ•°æ®å¤±è´¥: {e}")

    def record_feedback(
        self,
        question: str,
        generated_sql: str,
        feedback: str,
        matched_tables: List[str],
        matched_fields: List[str] = None,
        matched_enums: List[str] = None,
        relevance_scores: Dict[str, float] = None,
        user_id: str = None,
        session_id: str = None
    ) -> str:
        """
        è®°å½•ç”¨æˆ·åé¦ˆ

        Args:
            question: ç”¨æˆ·é—®é¢˜
            generated_sql: ç”Ÿæˆçš„SQL
            feedback: åé¦ˆç±»å‹ ("positive" æˆ– "negative")
            matched_tables: åŒ¹é…åˆ°çš„è¡¨
            matched_fields: åŒ¹é…åˆ°çš„å­—æ®µ
            matched_enums: åŒ¹é…åˆ°çš„æšä¸¾
            relevance_scores: å„è¡¨çš„ç›¸ä¼¼åº¦åˆ†æ•°
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID

        Returns:
            query_id: åé¦ˆè®°å½•ID
        """
        query_id = hashlib.md5(f"{question}{time.time()}".encode()).hexdigest()[:12]

        feedback_record = QueryFeedback(
            query_id=query_id,
            question=question,
            generated_sql=generated_sql,
            feedback=feedback,
            feedback_time=datetime.now(),
            user_id=user_id,
            session_id=session_id,
            matched_tables=matched_tables or [],
            matched_fields=matched_fields or [],
            matched_enums=matched_enums or [],
            relevance_scores=relevance_scores or {}
        )

        self.feedback_history.append(feedback_record)

        self._learn_from_feedback(feedback_record)

        self._save_data()

        SQLBotLogUtil.info(f"åé¦ˆå·²è®°å½•: {query_id} - {feedback}")

        return query_id

    def _learn_from_feedback(self, feedback: QueryFeedback):
        """ä»åé¦ˆä¸­å­¦ä¹ """
        if feedback.feedback == "negative":
            self._learn_from_failure(feedback)
        else:
            self._learn_from_success(feedback)

    def _learn_from_success(self, feedback: QueryFeedback):
        """ä»æˆåŠŸæ¡ˆä¾‹ä¸­å­¦ä¹ """
        keywords = self._extract_keywords(feedback.question)

        for table in feedback.matched_tables:
            self.table_stats[table]['success'] += 1

            for keyword in keywords:
                if keyword not in self.keyword_weights:
                    self.keyword_weights[keyword] = KeywordWeight(
                        keyword=keyword,
                        weight=1.0
                    )

                kw = self.keyword_weights[keyword]
                kw.success_count += 1
                kw.weight = min(2.0, 1.0 + (kw.success_count - kw.failure_count) * 0.1)

                if table not in kw.table_associations:
                    kw.table_associations[table] = 0
                kw.table_associations[table] += 1

        pattern_key = self._create_pattern_key(feedback.matched_tables, feedback.matched_fields)
        if pattern_key not in self.learned_patterns:
            embedding = self._get_question_embedding(feedback.question)
            self.learned_patterns[pattern_key] = LearnedPattern(
                pattern_id=pattern_key,
                question_pattern=feedback.question[:100],
                matched_table=feedback.matched_tables[0] if feedback.matched_tables else "",
                success_count=1,
                keywords=keywords,
                embeddings=embedding.tolist() if embedding is not None else None
            )
        else:
            pattern = self.learned_patterns[pattern_key]
            pattern.success_count += 1
            pattern.confidence = pattern.success_count / (pattern.success_count + pattern.failure_count + 1)
            pattern.last_updated = datetime.now()

        self._add_to_memory(feedback)

    def _learn_from_failure(self, feedback: QueryFeedback):
        """ä»å¤±è´¥æ¡ˆä¾‹ä¸­å­¦ä¹ """
        keywords = self._extract_keywords(feedback.question)

        for table in feedback.matched_tables:
            self.table_stats[table]['failure'] += 1

            for keyword in keywords:
                if keyword not in self.keyword_weights:
                    self.keyword_weights[keyword] = KeywordWeight(
                        keyword=keyword,
                        weight=1.0
                    )

                kw = self.keyword_weights[keyword]
                kw.failure_count += 1
                kw.weight = max(0.1, 1.0 - (kw.failure_count - kw.success_count) * 0.1)

        pattern_key = self._create_pattern_key(feedback.matched_tables, feedback.matched_fields)
        if pattern_key in self.learned_patterns:
            pattern = self.learned_patterns[pattern_key]
            pattern.failure_count += 1
            pattern.confidence = pattern.success_count / (pattern.success_count + pattern.failure_count + 1)
            pattern.last_updated = datetime.now()

    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯"""
        import re
        text = re.sub(r'[ï¼Œã€‚ï¼ï¼Ÿã€ï¼šï¼›""''ã€ã€‘ï¼ˆï¼‰\(\)\[\]]', ' ', text)
        words = text.split()

        stopwords = {'çš„', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ', 'æŸ¥è¯¢', 'ç»Ÿè®¡', 'è·å–', 'è¯·', 'å¸®æˆ‘'}

        keywords = []
        for word in words:
            word = word.strip()
            if word and len(word) >= 2 and word not in stopwords:
                keywords.append(word)

        return keywords

    def _create_pattern_key(self, tables: List[str], fields: List[str]) -> str:
        """åˆ›å»ºæ¨¡å¼é”®"""
        key_parts = sorted(set(tables + (fields or [])))
        return '|'.join(key_parts[:3])

    def _get_question_embedding(self, question: str) -> Optional[np.ndarray]:
        """è·å–é—®é¢˜çš„å‘é‡è¡¨ç¤º"""
        model = self._get_embedding_model()
        if model is None:
            return None
        try:
            embedding = model.embed_query(question)
            if isinstance(embedding, list):
                return np.array(embedding)
            return embedding
        except Exception:
            return None

    def _add_to_memory(self, feedback: QueryFeedback):
        """æ·»åŠ åˆ°è®°å¿†åº“"""
        keywords = self._extract_keywords(feedback.question)
        embedding = self._get_question_embedding(feedback.question)

        if not embedding is None:
            memory_id = hashlib.md5(feedback.question.encode()).hexdigest()[:16]

            self.memory_bank[memory_id] = MemoryItem(
                question=feedback.question,
                sql=feedback.generated_sql,
                table=feedback.matched_tables[0] if feedback.matched_tables else "",
                keywords=keywords,
                embedding=embedding.tolist(),
                success_count=1,
                last_used=datetime.now()
            )

            if len(self.memory_bank) > 1000:
                self._prune_memory()

    def _prune_memory(self):
        """æ¸…ç†ä½è´¨é‡çš„è®°å¿†"""
        sorted_items = sorted(
            self.memory_bank.items(),
            key=lambda x: (x[1].success_count, x[1].last_used),
            reverse=True
        )
        self.memory_bank = dict(sorted_items[:1000])

    def get_enhanced_weights(self, keywords: List[str]) -> Dict[str, float]:
        """
        è·å–å¢å¼ºåçš„å…³é”®è¯æƒé‡

        Args:
            keywords: åŸå§‹å…³é”®è¯åˆ—è¡¨

        Returns:
            å¢å¼ºåçš„æƒé‡å­—å…¸
        """
        enhanced = {}
        for keyword in keywords:
            if keyword in self.keyword_weights:
                kw = self.keyword_weights[keyword]
                enhanced[keyword] = kw.weight
            else:
                enhanced[keyword] = 1.0
        return enhanced

    def get_similar_questions(self, question: str, top_k: int = 5) -> List[Tuple[str, str, float]]:
        """
        è·å–ç›¸ä¼¼çš„é—®é¢˜

        Args:
            question: å½“å‰é—®é¢˜
            top_k: è¿”å›æ•°é‡

        Returns:
            (é—®é¢˜, SQL, ç›¸ä¼¼åº¦) åˆ—è¡¨
        """
        embedding = self._get_question_embedding(question)
        if embedding is None:
            return []

        results = []
        for memory_id, item in self.memory_bank.items():
            if item.embedding:
                item_embedding = np.array(item.embedding)
                similarity = np.dot(embedding, item_embedding) / (
                    np.linalg.norm(embedding) * np.linalg.norm(item_embedding) + 1e-8
                )
                results.append((item.question, item.sql, float(similarity)))

        results.sort(key=lambda x: x[2], reverse=True)
        return results[:top_k]

    def get_recommended_keywords(self, question: str) -> List[str]:
        """
        æ ¹æ®å†å²æ¨èå…³é”®è¯

        Args:
            question: ç”¨æˆ·é—®é¢˜

        Returns:
            æ¨èå…³é”®è¯åˆ—è¡¨
        """
        keywords = self._extract_keywords(question)
        recommended = []

        for keyword in keywords:
            if keyword in self.keyword_weights:
                kw = self.keyword_weights[keyword]
                if kw.weight > 1.2:
                    recommended.append(f"{keyword}*")

        return recommended

    def get_table_suggestions(self, question: str) -> List[Tuple[str, float]]:
        """
        æ ¹æ®å†å²æ¨èå¯èƒ½ç›¸å…³çš„è¡¨

        Args:
            question: ç”¨æˆ·é—®é¢˜

        Returns:
            (è¡¨å, ç½®ä¿¡åº¦) åˆ—è¡¨
        """
        keywords = self._extract_keywords(question)
        table_scores: Dict[str, float] = defaultdict(float)

        for keyword in keywords:
            if keyword in self.keyword_weights:
                kw = self.keyword_weights[keyword]
                for table, count in kw.table_associations.items():
                    table_scores[table] += kw.weight * count

        results = sorted(table_scores.items(), key=lambda x: x[1], reverse=True)
        return results[:5]

    def get_learning_stats(self) -> Dict[str, Any]:
        """è·å–å­¦ä¹ ç»Ÿè®¡ä¿¡æ¯"""
        total_feedback = len(self.feedback_history)
        positive = sum(1 for f in self.feedback_history if f.feedback == "positive")
        negative = total_feedback - positive

        top_keywords = sorted(
            self.keyword_weights.items(),
            key=lambda x: x[1].weight,
            reverse=True
        )[:10]

        top_patterns = sorted(
            self.learned_patterns.items(),
            key=lambda x: x[1].success_count,
            reverse=True
        )[:5]

        return {
            "total_feedback": total_feedback,
            "positive_feedback": positive,
            "negative_feedback": negative,
            "success_rate": positive / total_feedback if total_feedback > 0 else 0,
            "learned_patterns": len(self.learned_patterns),
            "keyword_weights": len(self.keyword_weights),
            "memory_items": len(self.memory_bank),
            "top_keywords": [
                {"keyword": k, "weight": v.weight, "success": v.success_count}
                for k, v in top_keywords
            ],
            "top_patterns": [
                {
                    "pattern": pattern.question_pattern[:50],
                    "success": pattern.success_count,
                    "confidence": pattern.confidence
                }
                for _, pattern in top_patterns
            ]
        }

    def analyze_query_patterns(self, days: int = 7) -> Dict[str, Any]:
        """åˆ†ææŸ¥è¯¢æ¨¡å¼"""
        cutoff = datetime.now() - timedelta(days=days)

        recent_feedback = [
            f for f in self.feedback_history
            if f.feedback_time > cutoff
        ]

        if not recent_feedback:
            return {"message": "æ²¡æœ‰è¶³å¤Ÿçš„åé¦ˆæ•°æ®"}

        table_performance = {}
        for feedback in recent_feedback:
            for table in feedback.matched_tables:
                if table not in table_performance:
                    table_performance[table] = {"success": 0, "failure": 0}
                if feedback.feedback == "positive":
                    table_performance[table]["success"] += 1
                else:
                    table_performance[table]["failure"] += 1

        common_mistakes = []
        for feedback in recent_feedback:
            if feedback.feedback == "negative":
                keywords = self._extract_keywords(feedback.question)
                common_mistakes.append({
                    "question": feedback.question,
                    "matched_tables": feedback.matched_tables,
                    "keywords": keywords
                })

        return {
            "period_days": days,
            "total_queries": len(recent_feedback),
            "success_rate": sum(1 for f in recent_feedback if f.feedback == "positive") / len(recent_feedback),
            "table_performance": table_performance,
            "common_mistakes": common_mistakes[:5]
        }

    def reset_learning_data(self):
        """é‡ç½®æ‰€æœ‰å­¦ä¹ æ•°æ®"""
        self.feedback_history = []
        self.learned_patterns = {}
        self.keyword_weights = {}
        self.memory_bank = {}
        self.table_stats = defaultdict(lambda: defaultdict(int))

        for name in ['feedback', 'patterns', 'keywords', 'memory']:
            filepath = self._get_file_path(name)
            if os.path.exists(filepath):
                os.remove(filepath)

        SQLBotLogUtil.info("è‡ªæˆ‘å­¦ä¹ æ•°æ®å·²é‡ç½®")


self_learning_engine = SelfLearningEngine()


def get_self_learning_engine() -> SelfLearningEngine:
    """è·å–è‡ªæˆ‘å­¦ä¹ å¼•æ“å®ä¾‹"""
    return self_learning_engine


def record_user_feedback(
    question: str,
    generated_sql: str,
    feedback: str,
    matched_tables: List[str],
    matched_fields: List[str] = None,
    matched_enums: List[str] = None,
    user_id: str = None
) -> str:
    """
    è®°å½•ç”¨æˆ·åé¦ˆçš„ä¾¿æ·å‡½æ•°

    Args:
        question: ç”¨æˆ·é—®é¢˜
        generated_sql: ç”Ÿæˆçš„SQL
        feedback: åé¦ˆ ("positive" æˆ– "negative")
        matched_tables: åŒ¹é…åˆ°çš„è¡¨
        matched_fields: åŒ¹é…åˆ°çš„å­—æ®µ
        matched_enums: åŒ¹é…åˆ°çš„æšä¸¾
        user_id: ç”¨æˆ·ID

    Returns:
        query_id: åé¦ˆè®°å½•ID
    """
    engine = get_self_learning_engine()
    return engine.record_feedback(
        question=question,
        generated_sql=generated_sql,
        feedback=feedback,
        matched_tables=matched_tables,
        matched_fields=matched_fields,
        matched_enums=matched_enums,
        user_id=user_id
    )


def get_similar_questions(question: str, top_k: int = 5) -> List[Tuple[str, str, float]]:
    """è·å–ç›¸ä¼¼é—®é¢˜çš„ä¾¿æ·å‡½æ•°"""
    engine = get_self_learning_engine()
    return engine.get_similar_questions(question, top_k)


def get_enhanced_weights(keywords: List[str]) -> Dict[str, float]:
    """è·å–å¢å¼ºæƒé‡çš„ä¾¿æ·å‡½æ•°"""
    engine = get_self_learning_engine()
    return engine.get_enhanced_weights(keywords)


def get_learning_stats() -> Dict[str, Any]:
    """è·å–å­¦ä¹ ç»Ÿè®¡çš„ä¾¿æ·å‡½æ•°"""
    engine = get_self_learning_engine()
    return engine.get_learning_stats()
